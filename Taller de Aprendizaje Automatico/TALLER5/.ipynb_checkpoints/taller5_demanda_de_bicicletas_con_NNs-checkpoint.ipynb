{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK9dmG7MSOya"
   },
   "source": [
    "#  <center> Taller  de Aprendizaje Automático </center>\n",
    "##  <center> Taller 5: Estimación de la demanda de bicicletas compartidas utilizando *Neural Networks*.  </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PjU4ItOTaGr"
   },
   "source": [
    "# Introducción\n",
    "\n",
    "En esta actividad se retomará el problema de la competencia [*Bike Sharing Demand*](https://www.kaggle.com/c/bike-sharing-demand) visto en el Taller 3.\n",
    "Esta vez las estimaciónes deben obtenerse utilizando la herramienta: *Multilayer Perceptron* (MLP). Es importante mantener la función *Root Mean Squared Logarithmic Error* (RMSLE) como medida de desempeño de manera de poder comparar los resultados con los obtenidos en el Taller 3.\n",
    "\n",
    "Tanto las preguntas teóricas como la parte práctica de esta actividad están ligadas al contenido del capítulo 10 (*Introduction to\n",
    "Artificial Neural Networks with\n",
    "Keras*) del libro del curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnXnqw5KS3zd"
   },
   "source": [
    "## Objetivos\n",
    "\n",
    "\n",
    "*   Trabajar con modelos MLP utilizando la librería [*Keras*](https://keras.io/api/).\n",
    "*   Probar algunas de las herramientas disponibles para la busqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "graphic-longitude"
   },
   "source": [
    "## Formas de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "similar-surgery"
   },
   "source": [
    "#### Opción 1: Trabajar localmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "616868da"
   },
   "source": [
    "##### Descarga de datos disponibles en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a76c306"
   },
   "source": [
    "Luego, para descargar el dataset de Demanda de Bicicletas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:45:00.703408Z",
     "start_time": "2022-04-06T08:44:59.289873Z"
    },
    "id": "a25f6679",
    "outputId": "d70c8c1e-530a-45ef-e259-f3addee20c02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Scripts\\kaggle.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\kaggle\\__init__.py\", line 6, in <module>\n",
      "    api.authenticate()\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 433, in authenticate\n",
      "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
      "OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\uriel\\.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e60a6af5"
   },
   "source": [
    "Descomprima el archivo descargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:45:00.781065Z",
     "start_time": "2022-04-06T08:45:00.769278Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.unpack_archive('./bike-sharing-demand.zip', './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efficient-thailand"
   },
   "source": [
    "#### Opción 2:  Trabajar en *Colab*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/TAA-fing/TAA-2025/blob/main/talleres/taller5_demanda_de_bicicletas_con_NNs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Ejecutar en Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compound-criminal"
   },
   "source": [
    "Se puede trabajar en Google Colab. Para ello es necesario contar con una cuenta de **google drive** y ejecutar un notebook almacenado en dicha cuenta. De lo contrario, no se conservarán los cambios realizados en la sesión. En caso de ya contar con una cuenta, se puede abrir el notebook y luego ir a `Archivo-->Guardar una copia en drive`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_rith_Skga5"
   },
   "source": [
    "La siguiente celda monta el disco personal del drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21875,
     "status": "ok",
     "timestamp": 1645451536176,
     "user": {
      "displayName": "Emiliano Acevedo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09255842080725499836"
     },
     "user_tz": 180
    },
    "id": "timely-power",
    "outputId": "9b878f94-05b8-4598-baa4-08a3e132868d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WC47WBdkeqj"
   },
   "source": [
    "A continuación, vaya a su cuenta de [Kaggle](https://www.kaggle.com/) (o cree una si aún no lo ha hecho), haga clic en el icono de perfil en la esquina superior derecha de la pantalla y seleccione \"Your Account\" en la lista desplegable. Luego, seleccione la viñeta \"Account\" y haga clic en \"Create new API token\". Entonces un archivo llamado kaggle.json se descargará automáticamente a su carpeta de descargas. Este archivo contiene sus credenciales de inicio de sesión para permitirle acceder a la API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "changing-enhancement"
   },
   "source": [
    "La siguiente celda realiza la configuración necesaria para obtener datos desde la plataforma Kaggle. Le solicitará que suba el archivo kaggle.json descargado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 31400,
     "status": "ok",
     "timestamp": 1645451632279,
     "user": {
      "displayName": "Emiliano Acevedo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09255842080725499836"
     },
     "user_tz": 180
    },
    "id": "convinced-person",
    "outputId": "59951021-dcb6-4622-e24e-062806a6ce7f"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from google.colab import files\n",
    "\n",
    "# El siguiente archivo solicitado es para habilitar la API de Kaggle en el entorno que está trabajando.\n",
    "# Este archivo se descarga entrando a su perfíl de Kaggle, en la sección API, presionando donde dice: Create New API Token\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "\n",
    "#Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fossil-australian"
   },
   "source": [
    "Una vez guardado el *token* se pueden descargar los datos, en este caso se bajarán los datos del dataset de Demanda de Bicicletas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:18:39.849067Z",
     "start_time": "2022-04-06T08:18:38.482792Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2104,
     "status": "ok",
     "timestamp": 1645451663400,
     "user": {
      "displayName": "Emiliano Acevedo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09255842080725499836"
     },
     "user_tz": 180
    },
    "id": "independent-eagle",
    "outputId": "bfe00bd3-81a5-487f-e60f-8b6e2ce1a189"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:19:07.842906Z",
     "start_time": "2022-04-06T08:18:41.405686Z"
    }
   },
   "outputs": [],
   "source": [
    "!unzip bike-sharing-demand.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta actividad se utilizarán algunas bibliotecas auxiliares que deberán ser instaladas. Ejecutar la siguiente celda hasta que se ejecute sin errores. En caso de error, se puede instalar el paquete faltante desde el notebook con el comando:\n",
    "\n",
    "`!pip install paquete_faltante`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:45:12.980879Z",
     "start_time": "2022-04-06T08:45:10.992955Z"
    }
   },
   "outputs": [],
   "source": [
    "#import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_submission = pd.read_csv('sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQi0j-avej0Q"
   },
   "source": [
    "## Parte 1 - Procesamiento de los datos\n",
    "\n",
    "Dado que ya se ha familiarizado con los datos, se implementa el mismo preprocesamiento que utilizó en el Taller 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras-tuner) (3.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras->keras-tuner) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests->keras-tuner) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras->keras-tuner) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Using cached numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.15.0-cp311-cp311-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.13.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\http\\client.py\", line 473, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from scikeras) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from scikeras) (1.6.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from keras>=3.2.0->scikeras) (24.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:45:17.367597Z",
     "start_time": "2022-04-06T08:45:17.333795Z"
    },
    "id": "WAJk7qqqphJa"
   },
   "outputs": [],
   "source": [
    "df_train['datetime'] = pd.to_datetime(df_train['datetime'])\n",
    "\n",
    "df_train['hour'] = df_train['datetime'].dt.hour\n",
    "df_train['weekday'] = df_train['datetime'].dt.weekday\n",
    "df_train['month'] = df_train['datetime'].dt.month \n",
    "df_train['year'] = df_train['datetime'].dt.year\n",
    "\n",
    "y_train_full = df_train['count']\n",
    "df_train = df_train.drop(['datetime', 'casual', 'registered', 'count'], axis=1) # hay que eliminarlas ya que tiene relación directa con la columna objetivo y no aparecen en el conjunto de *test*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dado que se trabajará con redes neuronales, ¿Cree conveniente realizar alguna modificación en el preprocesamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:45:19.115054Z",
     "start_time": "2022-04-06T08:45:19.108573Z"
    },
    "id": "3RotPZI9O67F"
   },
   "outputs": [],
   "source": [
    "Si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyhdy7JagA0k"
   },
   "source": [
    "## Parte 2 - Multilayer Perceptron (MLP)\n",
    "\n",
    "Siguiendo el ejemplo de la sección *Building a Regression MLP Using the Sequential API*:\n",
    "\n",
    "\n",
    "*   Implementar un estimador manteniendo los hiperparámetros del ejemplo.\n",
    "*   ¿Cuál es la cantidad total de parámetros entrenables de la red?\n",
    "*   Seleccionar aleatoriamente un *10%* de los datos para validación, y graficar la función de *loss* (*Mean Squared Logarithmic Error*) de entrenamiento y validación.\n",
    "\n",
    "*Nota: Observe que en el ejemplo se agrega una capa de normalización*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_full_scaled = scaler_y.fit_transform(y_train_full.to_numpy().reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full2, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_full_scaled, train_size=0.9\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full2, train_size=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1117 - msle: 0.1117 - val_loss: 0.0919 - val_msle: 0.0919\n",
      "Epoch 2/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0799 - msle: 0.0799 - val_loss: 0.0789 - val_msle: 0.0789\n",
      "Epoch 3/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0668 - msle: 0.0668 - val_loss: 0.0677 - val_msle: 0.0677\n",
      "Epoch 4/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0567 - msle: 0.0567 - val_loss: 0.0587 - val_msle: 0.0587\n",
      "Epoch 5/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0482 - msle: 0.0482 - val_loss: 0.0502 - val_msle: 0.0502\n",
      "Epoch 6/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0415 - msle: 0.0415 - val_loss: 0.0450 - val_msle: 0.0450\n",
      "Epoch 7/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - msle: 0.0351 - val_loss: 0.0379 - val_msle: 0.0379\n",
      "Epoch 8/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - msle: 0.0298 - val_loss: 0.0329 - val_msle: 0.0329\n",
      "Epoch 9/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0257 - msle: 0.0257 - val_loss: 0.0288 - val_msle: 0.0288\n",
      "Epoch 10/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0217 - msle: 0.0217 - val_loss: 0.0270 - val_msle: 0.0270\n",
      "Epoch 11/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0190 - msle: 0.0190 - val_loss: 0.0234 - val_msle: 0.0234\n",
      "Epoch 12/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0167 - msle: 0.0167 - val_loss: 0.0213 - val_msle: 0.0213\n",
      "Epoch 13/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0155 - msle: 0.0155 - val_loss: 0.0203 - val_msle: 0.0203\n",
      "Epoch 14/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0145 - msle: 0.0145 - val_loss: 0.0192 - val_msle: 0.0192\n",
      "Epoch 15/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0141 - msle: 0.0141 - val_loss: 0.0191 - val_msle: 0.0191\n",
      "Epoch 16/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0128 - msle: 0.0128 - val_loss: 0.0181 - val_msle: 0.0181\n",
      "Epoch 17/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0124 - msle: 0.0124 - val_loss: 0.0182 - val_msle: 0.0182\n",
      "Epoch 18/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0119 - msle: 0.0119 - val_loss: 0.0181 - val_msle: 0.0181\n",
      "Epoch 19/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0116 - msle: 0.0116 - val_loss: 0.0180 - val_msle: 0.0180\n",
      "Epoch 20/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0116 - msle: 0.0116 - val_loss: 0.0179 - val_msle: 0.0179\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0150 - msle: 0.0150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "#norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "#norm_layer,\n",
    "tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"msle\", optimizer=optimizer, metrics=[\"msle\"])\n",
    "#norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(\n",
    "figsize=(8, 5), xlim=[0, 20], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
    "style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,405</span> (67.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,405\u001b[0m (67.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,801</span> (22.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,801\u001b[0m (22.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,604</span> (45.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m11,604\u001b[0m (45.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.96220302]\n",
      " [-1.01345948]\n",
      " [ 0.44400787]\n",
      " ...\n",
      " [-0.64909264]\n",
      " [ 2.72958166]\n",
      " [-0.99137664]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min label: -1.0521044484722468, Max label: 4.3361081667641255\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min label: {y_train.min()}, Max label: {y_train.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzchTK1jrIxA"
   },
   "source": [
    "## Parte 3 - Ajuste fino\n",
    "\n",
    "Siguiendo el ejemplo de la sección *Fine-Tuning Neural Network Hyperparameters*:\n",
    "\n",
    "\n",
    "*   Utilizar la herramienta *RandomSearch* de *KerasTuner* para la busqueda de hiperparámetros del modelo implementado en *keras*. \n",
    "*   Probar el *tip* que se sugiere en la sección *Number of Neurons per Hidden Layer* y comentar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m param_distribs = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel__n_hidden\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel__n_neurons\u001b[39m\u001b[33m\"\u001b[39m: np.arange(\u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m20\u001b[39m]\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=\u001b[32m10\u001b[39m, cv=\u001b[32m4\u001b[39m, verbose=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mrnd_search_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMejores parámetros:\u001b[39m\u001b[33m\"\u001b[39m, rnd_search_cv.best_params_)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMejor score (MSLE promedio en CV):\u001b[39m\u001b[33m\"\u001b[39m, rnd_search_cv.best_score_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\comet_ml\\monkey_patching.py:304\u001b[39m, in \u001b[36mEntrypoint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    299\u001b[39m             LOGGER.debug(\n\u001b[32m    300\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mException calling after callback \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, callback, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    301\u001b[39m             )\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_raised\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m return_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\comet_ml\\monkey_patching.py:275\u001b[39m, in \u001b[36mEntrypoint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m exception_raised = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     return_value = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    277\u001b[39m     exception_raised = exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:933\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    929\u001b[39m params = _check_method_params(X, params=params)\n\u001b[32m    931\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._get_routed_params_for_fit(params)\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m cv_orig = check_cv(\u001b[38;5;28mself\u001b[39m.cv, y, classifier=\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    934\u001b[39m n_splits = cv_orig.get_n_splits(X, y, **routed_params.splitter.split)\n\u001b[32m    936\u001b[39m base_estimator = clone(\u001b[38;5;28mself\u001b[39m.estimator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\sklearn\\base.py:1237\u001b[39m, in \u001b[36mis_classifier\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m   1230\u001b[39m     warnings.warn(\n\u001b[32m   1231\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect.stack()[\u001b[32m0\u001b[39m][\u001b[32m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1232\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1233\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1234\u001b[39m     )\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33m_estimator_type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m.estimator_type == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[39m, in \u001b[36mget_tags\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator).mro()):\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         sklearn_tags_provider[klass] = \u001b[43mklass\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    431\u001b[39m         class_order.append(klass)\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_more_tags\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\sklearn\\base.py:613\u001b[39m, in \u001b[36mRegressorMixin.__sklearn_tags__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     tags = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[32m    614\u001b[39m     tags.estimator_type = \u001b[33m\"\u001b[39m\u001b[33mregressor\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m     tags.regressor_tags = RegressorTags()\n",
      "\u001b[31mAttributeError\u001b[39m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"model__n_hidden\": [1, 2, 3],\n",
    "    \"model__n_neurons\": np.arange(1, 100, 2),\n",
    "    \"model__learning_rate\": [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [20]\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=4, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", rnd_search_cv.best_params_)\n",
    "print(\"Mejor score (MSLE promedio en CV):\", rnd_search_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=2, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "    sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation= \"relu\"))\n",
    "    model.compile(loss=\"msle\", optimizer=optimizer, metrics=[\"msle\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y_train: -1.0521044484722468\n",
      "min y_valid: -1.0521044484722468\n"
     ]
    }
   ],
   "source": [
    "print(\"min y_train:\", y_train.min())\n",
    "print(\"min y_valid:\", y_valid.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from bike_regression_tuning\\random_search\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_mae\",  # métrica de validación para minimizar\n",
    "    max_trials=10,\n",
    "    overwrite=False,\n",
    "    directory=\"bike_regression_tuning\",\n",
    "    project_name=\"random_search\",\n",
    "    seed=42\n",
    ")\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'n_hidden': 4, 'n_neurons': 74, 'learning_rate': 0.00905127409782462, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Obtener el mejor modelo y los mejores hiperparámetros\n",
    "best_model = random_search_tuner.get_best_models(num_models=1)[0]\n",
    "best_hparams = random_search_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_hparams.values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmUt2QrywG60"
   },
   "source": [
    "## Parte 4 - Ajuste fino (Optuna)\n",
    "\n",
    "*   Utilizar *Optuna* para la busqueda de hiperparámetros del modelo en *Keras*. Se le sugiere seguir uno de los siguientes ejemplos: [*keras_simple*](https://github.com/optuna/optuna-examples/blob/main/keras/keras_simple.py),  [OptunaSearchCV](https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_optuna_search_cv_simple.py).\n",
    "\n",
    "*Nota: Optuna puede utilizarse para optimizar otras técnicas por fuera de las redes neuronales.*\n",
    "\n",
    "*Nota2: Keras Tuner permite realizar Optimización bayesiana.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DM4D3m-1X64",
    "outputId": "b2ed6754-9b75-4a83-8e61-c3e8394b613a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optuna) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optuna) (24.2)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\uriel\\miniconda3\\envs\\taa-py311\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 29.8 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl (295 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 greenlet-3.2.0 optuna-4.3.0 sqlalchemy-2.0.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uriel\\miniconda3\\envs\\TAA-py311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-17 21:51:53,152] A new study created in memory with name: no-name-938bb20b-b41e-4d41-aa0c-fd914d2b105d\n",
      "[I 2025-04-17 21:52:18,769] Trial 0 finished with value: 0.180355042219162 and parameters: {'n_hidden': 4, 'n_neurons': 212, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00024057472957103392}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:52:40,033] Trial 1 finished with value: 0.27051883935928345 and parameters: {'n_hidden': 4, 'n_neurons': 83, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00014866414980804294}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:53:02,478] Trial 2 finished with value: 0.4067036807537079 and parameters: {'n_hidden': 5, 'n_neurons': 176, 'activation': 'tanh', 'optimizer': 'sgd', 'learning_rate': 0.004542965157343365}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:53:19,433] Trial 3 finished with value: 0.5989143252372742 and parameters: {'n_hidden': 1, 'n_neurons': 116, 'activation': 'tanh', 'optimizer': 'sgd', 'learning_rate': 0.00017142092549269494}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:53:38,801] Trial 4 finished with value: 0.5219628810882568 and parameters: {'n_hidden': 5, 'n_neurons': 58, 'activation': 'relu', 'optimizer': 'sgd', 'learning_rate': 0.0005813893910733637}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:53:55,454] Trial 5 finished with value: 0.5760576128959656 and parameters: {'n_hidden': 1, 'n_neurons': 107, 'activation': 'relu', 'optimizer': 'sgd', 'learning_rate': 0.00021992221918788198}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:54:16,301] Trial 6 finished with value: 0.5589916706085205 and parameters: {'n_hidden': 3, 'n_neurons': 243, 'activation': 'relu', 'optimizer': 'sgd', 'learning_rate': 0.0002550609278415563}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:54:35,035] Trial 7 finished with value: 0.43056780099868774 and parameters: {'n_hidden': 3, 'n_neurons': 49, 'activation': 'tanh', 'optimizer': 'sgd', 'learning_rate': 0.006675810386670661}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:54:58,935] Trial 8 finished with value: 0.18693196773529053 and parameters: {'n_hidden': 5, 'n_neurons': 116, 'activation': 'tanh', 'optimizer': 'adam', 'learning_rate': 0.0007334745720759194}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:55:20,665] Trial 9 finished with value: 0.45112547278404236 and parameters: {'n_hidden': 4, 'n_neurons': 186, 'activation': 'tanh', 'optimizer': 'sgd', 'learning_rate': 0.003768536475133093}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:55:41,903] Trial 10 finished with value: 0.18151628971099854 and parameters: {'n_hidden': 2, 'n_neurons': 244, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0014501916776987608}. Best is trial 0 with value: 0.180355042219162.\n",
      "[I 2025-04-17 21:56:04,518] Trial 11 finished with value: 0.17846643924713135 and parameters: {'n_hidden': 2, 'n_neurons': 248, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0014853731390603749}. Best is trial 11 with value: 0.17846643924713135.\n",
      "[I 2025-04-17 21:56:25,418] Trial 12 finished with value: 0.18040268123149872 and parameters: {'n_hidden': 2, 'n_neurons': 206, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.001665720739607723}. Best is trial 11 with value: 0.17846643924713135.\n",
      "[I 2025-04-17 21:56:48,482] Trial 13 finished with value: 0.17529775202274323 and parameters: {'n_hidden': 3, 'n_neurons': 216, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.000500663333342019}. Best is trial 13 with value: 0.17529775202274323.\n",
      "[I 2025-04-17 21:57:09,261] Trial 14 finished with value: 0.2138366997241974 and parameters: {'n_hidden': 2, 'n_neurons': 166, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0005199162890341071}. Best is trial 13 with value: 0.17529775202274323.\n",
      "[I 2025-04-17 21:57:31,108] Trial 15 finished with value: 0.18522587418556213 and parameters: {'n_hidden': 2, 'n_neurons': 251, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0019107260333960578}. Best is trial 13 with value: 0.17529775202274323.\n",
      "[I 2025-04-17 21:57:54,343] Trial 16 finished with value: 0.17371641099452972 and parameters: {'n_hidden': 3, 'n_neurons': 218, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00041952380923834055}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 21:58:15,808] Trial 17 finished with value: 0.3349974453449249 and parameters: {'n_hidden': 3, 'n_neurons': 147, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00010262308603725021}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 21:58:40,995] Trial 18 finished with value: 0.1755446046590805 and parameters: {'n_hidden': 4, 'n_neurons': 215, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00042882050510429693}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 21:59:05,283] Trial 19 finished with value: 0.18069031834602356 and parameters: {'n_hidden': 3, 'n_neurons': 193, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00036287097074608914}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 21:59:30,199] Trial 20 finished with value: 0.18703436851501465 and parameters: {'n_hidden': 3, 'n_neurons': 154, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0009915314332713135}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 22:00:01,069] Trial 21 finished with value: 0.17785795032978058 and parameters: {'n_hidden': 4, 'n_neurons': 225, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00038853875120387483}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 22:00:30,509] Trial 22 finished with value: 0.1832031011581421 and parameters: {'n_hidden': 4, 'n_neurons': 221, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.00039639865705123396}. Best is trial 16 with value: 0.17371641099452972.\n",
      "[I 2025-04-17 22:00:55,332] Trial 23 finished with value: 0.17159537971019745 and parameters: {'n_hidden': 4, 'n_neurons': 202, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0009121810406881971}. Best is trial 23 with value: 0.17159537971019745.\n",
      "[I 2025-04-17 22:01:18,185] Trial 24 finished with value: 0.19287893176078796 and parameters: {'n_hidden': 3, 'n_neurons': 194, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0007533697377773938}. Best is trial 23 with value: 0.17159537971019745.\n",
      "[I 2025-04-17 22:01:43,865] Trial 25 finished with value: 0.194242462515831 and parameters: {'n_hidden': 4, 'n_neurons': 230, 'activation': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0010209210979047465}. Best is trial 23 with value: 0.17159537971019745.\n",
      "[I 2025-04-17 22:02:06,479] Trial 26 finished with value: 0.1906387358903885 and parameters: {'n_hidden': 3, 'n_neurons': 168, 'activation': 'tanh', 'optimizer': 'adam', 'learning_rate': 0.0009825855453538931}. Best is trial 23 with value: 0.17159537971019745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de trials: 27\n",
      "Mejor trial:\n",
      "  MAE: 0.17159537971019745\n",
      "  Hiperparámetros:\n",
      "    n_hidden: 4\n",
      "    n_neurons: 202\n",
      "    activation: relu\n",
      "    optimizer: adam\n",
      "    learning_rate: 0.0009121810406881971\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.backend import clear_session\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCHSIZE = 32\n",
    "\n",
    "def objective(trial):\n",
    "    clear_session()\n",
    "\n",
    "    # Sugerencias de hiperparámetros\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 1, 5)\n",
    "    n_neurons = trial.suggest_int(\"n_neurons\", 32, 256)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Construcción del modelo\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train.shape[1:]))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "    model.add(Dense(1))  # Salida para regresión\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        shuffle=True,\n",
    "        batch_size=BATCHSIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluamos en validación\n",
    "    loss, mae = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    return mae  # minimizar MAE\n",
    "\n",
    "# Ejecución del estudio\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, timeout=600)  # podés ajustar esto\n",
    "\n",
    "# Resultados\n",
    "print(\"Número de trials:\", len(study.trials))\n",
    "print(\"Mejor trial:\")\n",
    "print(\"  MAE:\", study.best_trial.value)\n",
    "print(\"  Hiperparámetros:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQoU9uS1lkM0"
   },
   "source": [
    "## Parte 5 - Pipeline\n",
    "\n",
    "\n",
    "\n",
    "*   Incorporar el estimador con mejor desempeño a un *pipeline* similar al implementado en el Taller 3. Puede ser útil la biblioteca [scikeras](https://adriangb.com/scikeras/stable/migration.html).\n",
    "*   Subir los resultados de los datos *test* a la página de la competencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXPwnG-rhKN2",
    "outputId": "1f40a4c8-e48a-4cdb-bf22-03e86d33ae5e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Taller5_demanda_de_bicicletas_con_NNs_solucion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cf9ed6eb9f80a715f753bb5491e7f879990bf814a1e5372a2cadce9b619c9f4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
